\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{enumerate}
\usepackage{amsmath}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\title{\huge \textbf{Stat 207 HW8} \\}
\author{\large Cheng Luo 912466499 \\ \large Fan Wu 912538518}
\maketitle

\newpage
\mbox{}
\newpage


\section{14.28}

\begin{enumerate}[(a)]

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{dat} \hlkwb{=} \hlkwd{read.table}\hlstd{(}\hlstr{"CH14PR14.txt"}\hlstd{)}
  \hlkwd{names}\hlstd{(dat)} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"Y"}\hlstd{,} \hlstr{"X1"}\hlstd{,} \hlstr{"X2"}\hlstd{,} \hlstr{"X3"}\hlstd{)}
  \hlstd{logit} \hlkwb{=} \hlkwd{glm}\hlstd{(Y} \hlopt{~} \hlstd{X1} \hlopt{+} \hlstd{X2 ,} \hlkwc{data} \hlstd{= dat,} \hlkwc{family} \hlstd{=} \hlstr{"binomial"}\hlstd{)}
  \hlstd{logitv} \hlkwb{=} \hlstd{logit}\hlopt{$}\hlstd{fitted.values}
  \hlstd{dat} \hlkwb{=} \hlstd{dat[}\hlkwd{order}\hlstd{(logitv), ]}
  \hlstd{a} \hlkwb{=} \hlkwd{rep}\hlstd{(}\hlnum{1}\hlopt{:}\hlnum{8}\hlstd{,} \hlkwc{each} \hlstd{=} \hlnum{20}\hlstd{)}
  \hlstd{a} \hlkwb{=} \hlstd{a[}\hlopt{-}\hlnum{1}\hlstd{]}
  \hlstd{b} \hlkwb{=} \hlkwd{split}\hlstd{(dat, a)}
  \hlstd{Oj1} \hlkwb{=} \hlkwd{sapply}\hlstd{(b,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{sum}\hlstd{(x[[}\hlnum{1}\hlstd{]])\})}
  \hlstd{Ej1} \hlkwb{=} \hlkwd{sapply}\hlstd{(}\hlkwd{split}\hlstd{(}\hlkwd{sort}\hlstd{(logitv), a), sum)}
  \hlstd{Oj0} \hlkwb{=} \hlkwd{sapply}\hlstd{(b,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{length}\hlstd{(x[[}\hlnum{1}\hlstd{]])}\hlopt{-}\hlkwd{sum}\hlstd{(x[[}\hlnum{1}\hlstd{]])\})}
  \hlstd{Ej0} \hlkwb{=} \hlkwd{sapply}\hlstd{(b,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{length}\hlstd{(x[[}\hlnum{1}\hlstd{]])\})}\hlopt{-}\hlstd{Ej1}
  \hlkwd{rbind}\hlstd{(Oj1, Ej1, Oj0, Ej0)}
\end{alltt}
\begin{verbatim}
##             1          2          3         4         5        6         7
## Oj1  0.000000  1.0000000  0.0000000  2.000000  1.000000  8.00000  2.000000
## Ej1  0.187472  0.5159059  0.9878718  1.512501  2.412695  3.44151  4.680125
## Oj0 19.000000 19.0000000 20.0000000 18.000000 19.000000 12.00000 18.000000
## Ej0 18.812528 19.4840941 19.0121282 18.487499 17.587305 16.55849 15.319875
##             8
## Oj1 10.000000
## Ej1 10.261919
## Oj0 10.000000
## Ej0  9.738081
\end{verbatim}
\begin{alltt}
  \hlstd{y} \hlkwb{=} \hlkwd{sapply}\hlstd{(}\hlkwd{split}\hlstd{(}\hlkwd{sort}\hlstd{(logitv), a), median)}
  \hlstd{x} \hlkwb{=} \hlstd{Ej1}\hlopt{/}\hlkwd{sapply}\hlstd{(b,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{length}\hlstd{(x[[}\hlnum{1}\hlstd{]])\})}
  \hlkwd{plot}\hlstd{(x, y)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-1-1} 

\end{knitrout}

\qquad The plot seems to be linear, it's consistent with a response function of monotonic sigmoidal shape.

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{X.squ} \hlkwb{=} \hlkwd{sum}\hlstd{((}\hlkwd{rbind}\hlstd{(Oj1, Oj0)}\hlopt{-}\hlkwd{rbind}\hlstd{(Ej1, Ej0))}\hlopt{^}\hlnum{2}\hlopt{/}\hlkwd{rbind}\hlstd{(Ej1, Ej0));X.squ}
\end{alltt}
\begin{verbatim}
## [1] 12.11578
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{center}
$H_0$:$E(Y)=[1+exp(-\beta_0-\beta_1 X1-\beta_2 X2)]^{-1}$

VS. $H_1$:$E(Y)  \ne [1+exp(-\beta_0-\beta_1 X1-\beta_2 X2)]^{-1}$

$X^2=\sum_j \sum_k \frac{(O_{jk}-E_{jk})^2}{E_{jk}} = 12.11578$

we can reject $H_0$ if $X^2 > \chi^2(0.95, 8-2)=12.5916$,otherwise reject$H_1$

so that reject $H_1$ because $X^2 <12.5916$, Pvalue is 0.05943518.
\end{center}

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{p} \hlkwb{=} \hlkwd{summary}\hlstd{(logit)}
  \hlstd{dr} \hlkwb{=} \hlstd{p}\hlopt{$}\hlstd{deviance.resid;dr}
\end{alltt}
\begin{verbatim}
##           1           2           3           4           5           6 
## -0.54602312 -0.51373259  1.15260237 -0.17517944 -0.18924467 -0.69185916 
##           7           8           9          10          11          12 
## -0.18367445 -0.73777334 -0.47288089 -0.35855218 -0.62785882 -0.33244658 
##          13          14          15          16          17          18 
## -0.49058859 -0.23345211 -0.11467682 -0.59485941 -0.85058862 -0.16214474 
##          19          20          21          22          23          24 
## -0.22270681 -0.13939895 -0.34822874 -0.28168748 -0.24470112 -0.09084127 
##          25          26          27          28          29          30 
## -0.50595282 -0.10798927 -0.69416101 -0.26781191 -0.83451488 -0.68109529 
##          31          32          33          34          35          36 
## -0.32519247 -0.45851859 -0.92893094 -0.53211206 -0.33897782 -0.16073331 
##          37          38          39          40          41          42 
##  0.74365705  1.38971984 -0.61999873 -0.41310085  1.89079347 -0.35679774 
##          43          44          45          46          47          48 
##  1.71627562 -0.33244658 -0.72647043 -0.32961191  2.84304938 -0.69729005 
##          49          50          51          52          53          54 
## -0.10990097 -0.18854516 -0.33530428 -0.21617318 -0.72171075 -0.59079687 
##          55          56          57          58          59          60 
##  2.23462510 -0.24806553 -0.42012390 -0.28029236 -1.30166964  2.00689554 
##          61          62          63          64          65          66 
##  1.10849910 -0.15933400 -0.68109529 -0.32124458 -0.10387671 -1.01249619 
##          67          68          69          70          71          72 
## -0.12087236 -0.36424502 -0.62497861  1.86302691 -0.23960963 -0.48311783 
##          73          74          75          76          77          78 
## -0.38006335  1.82187884 -1.44789883 -0.84697959 -0.83715068 -0.35248880 
##          79          80          81          82          83          84 
## -0.58403320 -0.45631940 -0.35855218  1.94481807 -0.72970910 -0.53462959 
##          85          86          87          88          89          90 
## -0.36293048 -1.15124676 -0.62286031 -0.65995923  2.34647993 -0.81345988 
##          91          92          93          94          95          96 
##  1.12311780 -0.17737218  1.27437628 -0.55762351 -0.49703364 -0.30029670 
##          97          98          99         100         101         102 
## -1.06493877 -0.71059309  0.95982139 -0.33201751 -0.67802259  1.90510957 
##         103         104         105         106         107         108 
## -0.45631940 -0.42162878 -0.12900059 -0.17648324 -0.19257415 -0.14876060 
##         109         110         111         112         113         114 
##  1.82969794 -0.32283373 -0.53091804 -0.13409993 -0.61013597 -0.72086770 
##         115         116         117         118         119         120 
## -0.50887859 -0.61087534 -0.16356841 -0.16073331 -0.12675915 -0.49293406 
##         121         122         123         124         125         126 
## -0.14931436 -0.21351074  1.84295971 -0.40421564  1.40875849 -0.30814469 
##         127         128         129         130         131         132 
## -0.40618549 -0.49528940 -0.51130056 -0.73777334 -0.28412789 -0.58877426 
##         133         134         135         136         137         138 
## -0.49703364 -1.22831729 -0.31850052  1.89079347 -0.29409388 -0.69416101 
##         139         140         141         142         143         144 
## -0.20982689 -0.48482421 -0.61925036 -0.28658859 -0.39176366 -0.48311783 
##         145         146         147         148         149         150 
## -1.11866815 -0.31307905 -0.35422338 -0.28065744 -0.72970910 -0.20982689 
##         151         152         153         154         155         156 
## -0.41110024 -0.42725579 -0.28554134 -0.38936035 -0.29263987 -0.25647527 
##         157         158         159 
##  0.42476809  0.86785144  1.67453806
\end{verbatim}
\begin{alltt}
  \hlstd{lows} \hlkwb{=} \hlkwd{lowess}\hlstd{(logitv, dr,} \hlnum{.7}\hlstd{,} \hlnum{0}\hlstd{);lows}
\end{alltt}
\begin{verbatim}
## $x
##   [1] 0.004117568 0.005380657 0.005813874 0.006020913 0.006553816
##   [6] 0.007278447 0.008001755 0.008286057 0.008951093 0.009668986
##  [11] 0.011003867 0.011085487 0.012613438 0.012834524 0.012834524
##  [16] 0.013059435 0.013288233 0.015226801 0.015452533 0.015607367
##  [21] 0.016726682 0.017571713 0.017617602 0.017747398 0.018371549
##  [26] 0.021773129 0.021773129 0.022535610 0.023094563 0.024494189
##  [31] 0.026882013 0.028298274 0.029495578 0.030299729 0.032354793
##  [36] 0.035226199 0.038520373 0.038618820 0.038897215 0.039560541
##  [41] 0.039947136 0.040234706 0.041915256 0.042323848 0.044087651
##  [46] 0.046367188 0.047827674 0.049456440 0.050290414 0.050776320
##  [51] 0.051501501 0.052872923 0.053626356 0.053761250 0.053761250
##  [56] 0.054663641 0.055833717 0.058830122 0.060233817 0.060809646
##  [61] 0.061668811 0.062257449 0.062257449 0.063737383 0.063737383
##  [66] 0.064184764 0.069677590 0.072999098 0.073868811 0.078447141
##  [71] 0.079182416 0.081029912 0.081787246 0.082350177 0.084469906
##  [76] 0.085049591 0.087232199 0.098877166 0.098877166 0.099783195
##  [81] 0.105784220 0.110149156 0.110149156 0.110883724 0.113379806
##  [86] 0.114401854 0.115431916 0.116197114 0.116197114 0.120141456
##  [91] 0.121446705 0.122531422 0.123624463 0.131455955 0.132006995
##  [96] 0.133171735 0.133478501 0.138491730 0.143988948 0.150896868
## [101] 0.156796870 0.159137868 0.160140341 0.162160612 0.162883307
## [106] 0.167369727 0.167369727 0.169836784 0.170211426 0.174474811
## [111] 0.174857529 0.176323549 0.176323549 0.177411440 0.178894230
## [116] 0.183003454 0.187514843 0.190211007 0.195692078 0.205353025
## [121] 0.207010578 0.207010578 0.212848500 0.214103167 0.214103167
## [126] 0.215812168 0.223121468 0.228813560 0.229282366 0.229282366
## [131] 0.231934023 0.233743020 0.233743020 0.238263628 0.238263628
## [136] 0.246094701 0.281693191 0.294047656 0.295601219 0.301407172
## [141] 0.303543886 0.350437581 0.370722956 0.380731597 0.401048267
## [146] 0.432802264 0.443961491 0.465118050 0.484534317 0.514661378
## [151] 0.529698682 0.532220820 0.540973420 0.571374597 0.630886977
## [156] 0.649433730 0.686202121 0.758423830 0.913735656
## 
## $y
##   [1] -0.088172324 -0.091193892 -0.092230236 -0.092725513 -0.094000327
##   [6] -0.095733792 -0.097464093 -0.098144200 -0.099735105 -0.101452449
##  [11] -0.104645759 -0.104841011 -0.108496180 -0.109025064 -0.109025064
##  [16] -0.109563096 -0.110097898 -0.114629173 -0.115156807 -0.115518722
##  [21] -0.118135047 -0.120110252 -0.120217515 -0.120520906 -0.121979817
##  [26] -0.129930790 -0.129930790 -0.131674467 -0.132952707 -0.136153436
##  [31] -0.141614024 -0.144852796 -0.147590845 -0.149429815 -0.154063466
##  [36] -0.160537759 -0.167965287 -0.168187260 -0.168814970 -0.170298321
##  [41] -0.171162836 -0.171805908 -0.175564005 -0.176477711 -0.180421979
##  [46] -0.185519548 -0.188785532 -0.192398644 -0.194248659 -0.195326551
##  [51] -0.196935228 -0.199977472 -0.201648820 -0.201948059 -0.201948059
##  [56] -0.203949843 -0.206545438 -0.213049988 -0.216097110 -0.217347109
##  [61] -0.219212173 -0.220489979 -0.220489979 -0.223702599 -0.223702599
##  [66] -0.224673765 -0.235828329 -0.242573485 -0.244070632 -0.251951891
##  [71] -0.253217613 -0.256397943 -0.257701638 -0.258386084 -0.260963379
##  [76] -0.261668196 -0.264321944 -0.225045104 -0.225045104 -0.219128032
##  [81] -0.179936676 -0.154186042 -0.154186042 -0.149852507 -0.135127045
##  [86] -0.129097542 -0.124673161 -0.121386438 -0.121386438 -0.104444471
##  [91] -0.098838092 -0.094178954 -0.092681826 -0.081955110 -0.082230732
##  [96] -0.082813318 -0.082966758 -0.085474301 -0.094606794 -0.103042914
## [101] -0.106432963 -0.107778064 -0.107963004 -0.108335712 -0.108469038
## [106] -0.109296710 -0.109296710 -0.112443596 -0.112921475 -0.118359689
## [111] -0.118847870 -0.120717870 -0.120717870 -0.122933578 -0.125953576
## [116] -0.134322830 -0.144160594 -0.150039986 -0.164525881 -0.191343995
## [121] -0.195401210 -0.195401210 -0.209690769 -0.212761835 -0.212761835
## [126] -0.214943573 -0.224274748 -0.224766647 -0.224807160 -0.224807160
## [131] -0.225036311 -0.225576792 -0.225576792 -0.226927430 -0.226927430
## [136] -0.228381345 -0.216959869 -0.223662497 -0.223545473 -0.223108129
## [141] -0.222011054 -0.180446860 -0.167914434 -0.163179048 -0.152280685
## [146] -0.128270882 -0.116634223 -0.092479525 -0.069813508 -0.033587453
## [151] -0.015034380 -0.011922648 -0.001158003  0.035380766  0.102419493
## [156]  0.122606667  0.162324533  0.242116112  0.426978094
\end{verbatim}
\end{kframe}
\end{knitrout}

\qquad It shows that the model is adequate, because the plot shows approximately a horizontal line with zero intercept.

\end{enumerate}

\section{14.39}

\begin{enumerate}[(a)]

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{dat} \hlkwb{=} \hlkwd{read.table}\hlstd{(}\hlstr{"CH14PR39.txt"}\hlstd{)}
  \hlkwd{names}\hlstd{(dat)} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"Y"}\hlstd{,} \hlstr{"X1"}\hlstd{,} \hlstr{"X2"}\hlstd{,} \hlstr{"X3"}\hlstd{,} \hlstr{"X4"}\hlstd{)}
  \hlstd{poi} \hlkwb{=} \hlkwd{glm}\hlstd{(Y} \hlopt{~} \hlstd{. ,} \hlkwc{data} \hlstd{= dat,} \hlkwc{family} \hlstd{=} \hlstr{"poisson"}\hlstd{)}
  \hlkwd{summary}\hlstd{(poi)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## glm(formula = Y ~ ., family = "poisson", data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1854  -0.7819  -0.2564   0.5449   2.3626  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.489467   0.336869   1.453  0.14623    
## X1          -1.069403   0.133154  -8.031 9.64e-16 ***
## X2          -0.046606   0.119970  -0.388  0.69766    
## X3           0.009470   0.002953   3.207  0.00134 ** 
## X4           0.008566   0.004312   1.986  0.04698 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 199.19  on 99  degrees of freedom
## Residual deviance: 108.79  on 95  degrees of freedom
## AIC: 377.29
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{displaymath}
\begin{split}
  b_0 = 0.489467 &\qquad s(b_0)=0.336869 \\
  b_1 = -1.069403 &\qquad  s(b_1)=0.133154 \\
  b_2 = -0.046606 &\qquad  s(b_2)=0.119970 \\
  b_3 = 0.009470 &\qquad  s(b_3)=0.002953 \\
  b_4 = 0.008566 &\qquad  s(b_4)=0.004312 \\
  \mu = exp(0.489467165 -1.069402551 X1 & -0.046606063 X2 +  0.009469987X3 +  0.008565829 X4)
\end{split}
\end{displaymath}

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{p} \hlkwb{=} \hlkwd{summary}\hlstd{(poi)}
  \hlstd{dr} \hlkwb{=} \hlstd{p}\hlopt{$}\hlstd{deviance.resid;dr}
\end{alltt}
\begin{verbatim}
##            1            2            3            4            5 
## -0.481563003 -0.632820229  0.485684782 -1.819828480  0.238302497 
##            6            7            8            9           10 
## -0.427206484 -1.574566470 -1.694831446 -0.190494237  0.372414202 
##           11           12           13           14           15 
##  0.290568448  0.917894609  0.618945304  0.710218879 -0.169117683 
##           16           17           18           19           20 
##  0.774212615  1.313966589  0.976533023 -0.284161510  0.281078819 
##           21           22           23           24           25 
##  0.671826155 -0.309823439 -0.585274974 -1.659501048 -1.653549229 
##           26           27           28           29           30 
##  0.545695411 -2.089197070 -1.825162331  0.283158353  1.066089357 
##           31           32           33           34           35 
##  0.338495236 -0.414912576 -0.276062096  2.097482057 -0.373770021 
##           36           37           38           39           40 
## -2.185378873  2.217373787 -0.269196968 -1.468917177 -0.490568471 
##           41           42           43           44           45 
## -0.243689445  2.287659410 -0.435460637 -0.171363655 -1.596370920 
##           46           47           48           49           50 
##  0.178588604 -1.840819930  1.313615961 -0.233624875 -1.576829772 
##           51           52           53           54           55 
## -0.652282150  2.177759158 -0.862317963 -1.223172388 -0.161565009 
##           56           57           58           59           60 
## -0.438457085 -0.817656201  0.002451800 -0.690070466 -0.932653968 
##           61           62           63           64           65 
## -0.532725622  0.400431092  1.326821516  0.569505372  0.589162479 
##           66           67           68           69           70 
##  0.222202292  1.991163395  0.134986579  1.163783804  0.890153115 
##           71           72           73           74           75 
## -0.398888037 -0.335860573 -0.843868576  1.065308951 -0.068529260 
##           76           77           78           79           80 
## -1.210403791  0.928316209 -0.803424449 -0.050707876 -0.817762385 
##           81           82           83           84           85 
##  0.544674549 -1.761754891 -0.562223893 -0.541853422  0.147418906 
##           86           87           88           89           90 
## -0.009840529 -0.337422359 -0.774688780 -1.383658148 -0.654757856 
##           91           92           93           94           95 
## -1.475851025 -0.722343228  2.362545161  1.391144309  1.262066676 
##           96           97           98           99          100 
##  0.117099736 -0.827717570 -0.345172951  0.048822205 -0.988857456
\end{verbatim}
\begin{alltt}
  \hlkwd{plot}\hlstd{(dr,} \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figure/unnamed-chunk-5-1} 

\end{knitrout}

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{logLik}\hlstd{(poi)}
\end{alltt}
\begin{verbatim}
## 'log Lik.' -183.6439 (df=5)
\end{verbatim}
\begin{alltt}
  \hlstd{poiR} \hlkwb{=} \hlkwd{glm}\hlstd{(Y} \hlopt{~} \hlstd{.}\hlopt{-}\hlstd{X2 ,} \hlkwc{data} \hlstd{= dat,} \hlkwc{family} \hlstd{=} \hlstr{"poisson"}\hlstd{)}
  \hlkwd{logLik}\hlstd{(poiR)}
\end{alltt}
\begin{verbatim}
## 'log Lik.' -183.7194 (df=4)
\end{verbatim}
\begin{alltt}
  \hlkwd{qchisq}\hlstd{(}\hlnum{1}\hlopt{-}\hlnum{0.05}\hlstd{,} \hlnum{5}\hlopt{-}\hlnum{4}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 3.841459
\end{verbatim}
\begin{alltt}
  \hlkwd{pchisq}\hlstd{(}\hlnum{0.151}\hlstd{,} \hlnum{1}\hlstd{,} \hlkwc{lower.tail} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.6975815
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{center}
$H_0$:$\beta_2=0$

VS. $H_1$:$\beta_2 \ne 0$

The full model: $\mu = exp(\beta_0 + \beta_1 X1 + \beta_2 X2 + \beta_3 X3 + \beta_4 X4) $

ln(L(F))= -183.6439

The reduced model: $\mu = exp(\beta_0 + \beta_1 X1 + \beta_3 X3 + \beta_4 X4) $

ln(L(R))= -183.7194

$G^2$ = -2(ln(L(R)-ln(L(F)))) = 0.151

we can reject $H_0$ if $G^2 > \chi^2(1-0.05, 5-4)=3.8415$,otherwise reject$H_1$

so that reject $H_1$ because $G^2 < 3.8415$,

therefore, X2 can be dropped from the regression model, and the P-value is 0.6975815.And the result is the same as the result we get in (b).
\end{center}

\item

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{summary}\hlstd{(poiR)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## glm(formula = Y ~ . - X2, family = "poisson", data = dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2152  -0.7512  -0.2594   0.5830   2.2893  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.443890   0.317289   1.399  0.16181    
## X1          -1.077770   0.131415  -8.201 2.38e-16 ***
## X3           0.009471   0.002957   3.203  0.00136 ** 
## X4           0.008979   0.004190   2.143  0.03209 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 199.19  on 99  degrees of freedom
## Residual deviance: 108.94  on 96  degrees of freedom
## AIC: 375.44
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}
\begin{alltt}
  \hlstd{b1} \hlkwb{=} \hlopt{-}\hlnum{1.077770}
  \hlstd{s1} \hlkwb{=} \hlnum{0.131415}
  \hlstd{z} \hlkwb{=} \hlkwd{qnorm}\hlstd{(}\hlnum{1}\hlopt{-}\hlnum{0.05}\hlopt{/}\hlnum{2}\hlstd{)}
  \hlkwd{c}\hlstd{(b1}\hlopt{-}\hlstd{s1}\hlopt{*}\hlstd{z, b1}\hlopt{+}\hlstd{s1}\hlopt{*}\hlstd{z)}
\end{alltt}
\begin{verbatim}
## [1] -1.3353387 -0.8202013
\end{verbatim}
\end{kframe}
\end{knitrout}

\qquad From summary(poiR), we get $s(b_1) = 0.131415, b_1 = -1.077770$, based on $b_k \pm z(1-\alpha/2)s{b_k}$, we conclude that we are 95 \% confident that $\beta_1$ is between -1.3353387 and -0.8202013. Because the confidence interval is smaller than 0, aerobic exercise reduce the frequency of falls when controlling for balance and strength.

\end{enumerate}

\section{14.44}

\begin{displaymath}
\begin{split}
  lnL(\beta_0, \beta_1) &= \sum_{i=1}^n y_i(\beta_0+\beta_1 X_i) - \sum_{i=1}^n(1+exp(\beta_0+\beta_1 X_i))\\
  \frac{\partial lnL}{\partial \beta_0} &= - \sum_{i=1}^n (Y_i-\frac{ exp(\beta_0+\beta_1 X_i)}{[1+exp(\beta_0+\beta_1 X_i)]^2})\\
  \frac{\partial lnL}{\partial \beta_1} &= - \sum_{i=1}^n (Y_i X_i - \frac{ exp(\beta_0+\beta_1 X_i)}{[1+exp(\beta_0+\beta_1 X_i)]^2})\\
  \frac{\partial^2 lnL}{\partial \beta_0^2} &= - \sum_{i=1}^n \frac{exp(\beta_0+\beta_1 X_i)}{[1+exp(\beta_0+\beta_1 X_i)]^2}\\
  \frac{\partial^2 lnL}{\partial \beta_1^2} &= - \sum_{i=1}^n \frac{X_i^2 exp(\beta_0+\beta_1 X_i)}{[1+exp(\beta_0+\beta_1 X_i)]^2}\\
  \frac{\partial^2 lnL}{\partial \beta_0 \partial \beta_1} &= - \sum_{i=1}^n \frac{X_i exp(\beta_0+\beta_1 X_i)}{[1+exp(\beta_0+\beta_1 X_i)]^2}\\
\end{split}
\end{displaymath}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{dat} \hlkwb{=} \hlkwd{read.table}\hlstd{(}\hlstr{"CH14TA01.txt"}\hlstd{)}
  \hlkwd{names}\hlstd{(dat)} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"X"}\hlstd{,} \hlstr{"Y"}\hlstd{,} \hlstr{"pi"}\hlstd{)}
  \hlstd{b0} \hlkwb{=} \hlopt{-}\hlnum{3.0597}
  \hlstd{b1} \hlkwb{=} \hlnum{0.1615}
  \hlstd{t} \hlkwb{=} \hlkwd{exp}\hlstd{(b0} \hlopt{+} \hlstd{b1}\hlopt{*}\hlstd{dat}\hlopt{$}\hlstd{X)}
  \hlstd{t1} \hlkwb{=} \hlkwd{sum}\hlstd{(t}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlstd{t)}\hlopt{^}\hlnum{2}\hlstd{);t1}
\end{alltt}
\begin{verbatim}
## [1] 4.176239
\end{verbatim}
\begin{alltt}
  \hlstd{t2} \hlkwb{=} \hlkwd{sum}\hlstd{((t} \hlopt{*} \hlstd{dat}\hlopt{$}\hlstd{X)}\hlopt{/}\hlstd{(}\hlnum{1} \hlopt{+} \hlstd{t)}\hlopt{^}\hlnum{2}\hlstd{);t2}
\end{alltt}
\begin{verbatim}
## [1] 74.57466
\end{verbatim}
\begin{alltt}
  \hlstd{t3} \hlkwb{=} \hlkwd{sum}\hlstd{(((dat}\hlopt{$}\hlstd{X)}\hlopt{^}\hlnum{2}\hlopt{*}\hlstd{t)}\hlopt{/}\hlstd{(}\hlnum{1} \hlopt{+} \hlstd{t)}\hlopt{^}\hlnum{2}\hlstd{);t3}
\end{alltt}
\begin{verbatim}
## [1] 1568.482
\end{verbatim}
\begin{alltt}
  \hlstd{H} \hlkwb{=} \hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(t, t1, t2, t3),} \hlnum{2}\hlstd{,} \hlnum{2}\hlstd{);H}
\end{alltt}
\begin{verbatim}
##           [,1]      [,2]
## [1,] 0.4499135 0.1236006
## [2,] 5.0723286 2.6586009
\end{verbatim}
\begin{alltt}
  \hlstd{H_1} \hlkwb{=} \hlkwd{solve}\hlstd{(H);H_1}
\end{alltt}
\begin{verbatim}
##           [,1]       [,2]
## [1,]  4.670787 -0.2171488
## [2,] -8.911367  0.7904346
\end{verbatim}
\begin{alltt}
  \hlkwd{sqrt}\hlstd{(}\hlnum{1.586}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 1.259365
\end{verbatim}
\begin{alltt}
  \hlkwd{sqrt}\hlstd{(}\hlnum{0.7904346}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.8890639
\end{verbatim}
\end{kframe}
\end{knitrout}

\qquad $H^{-1}$ we get after rootsquare is the same as the estimated standard deviation in table 14.1(b)

\section{14.45}

\begin{displaymath}
\begin{split}
  Y_i &= \frac{\gamma_0}{1 + \gamma_1 exp(\gamma_2 X_i)} + \epsilon_i \\
  E(Y_i) &= \frac{\gamma_0}{1 + \gamma_1 exp(\gamma_2 X_i)} \\
  \text{if} &\gamma_0 = 1 \\
  E(Y_i) &= \frac{1}{1 + \gamma_1 exp(\gamma_2 X_i)} \\
         &= \frac{1}{1 + exp(ln\gamma_1 + \gamma_2 X_i)} \\
         &= \frac{1}{1 + exp(-\beta_0 - \beta_1 X_i)} \\
         &= \frac{exp(\beta_0 + \beta_1 X_i)}{1+exp(\beta_0 + \beta_1 X_i)}\\
  \text{if} &\gamma_1 = exp(-\beta_0) , \gamma_2 = -\beta_1\\       
\end{split}
\end{displaymath}

\section{14.46}

\begin{displaymath}
\begin{split}
  E(Y) &= [1 + exp(-\beta_0-\beta_1 X_1 - \beta_2 X_2 - \beta_3 X_1 X_2)]^{-1} \\
  \pi^{'}(X_1)  &= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 \\
  \pi^{'}(X_1 + 1)  &= \beta_0 + \beta_1 (X_1 + 1) + \beta_2 X_2 + \beta_3 (X_1 + 1) X_2 \\ 
  \pi^{'}(X_1 + 1) - \pi^{'}(X_1) &= ln(odds ratio) = \beta_1 X_1 + \beta_3 X_1 X_2\\
  \text{ Hence the odds ratio for X1 is } & exp(\beta_1 X_1 + \beta_3 X_1 X_2) \text{therefore, they are different.} \\
\end{split}
\end{displaymath}

\section{14.47}

\begin{displaymath}
\begin{split}
  \pi &= 1 - exp[-exp(\frac{X_i-\gamma_0}{\gamma_1})] \\
  1 - \pi &= exp[-exp(\frac{X_i-\gamma_0}{\gamma_1})] \\
  ln[-ln(1-\pi)] &= -\frac{\gamma_0}{\gamma_1} + \frac{1}{\gamma_1} X_i\\
                 &= \beta_0 + \beta_1 X_i  
\end{split}
\end{displaymath}

\end{document}
